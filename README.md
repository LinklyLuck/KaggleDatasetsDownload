# Kaggle CSV Dataset Collector

A robust Python pipeline for **collecting, filtering, deduplicating, and indexing CSV datasets from Kaggle at scale**.

This project is designed for building a **high-quality tabular data pool** with strict constraints on dataset size, CSV structure, and per-dataset diversity.

---

## Features

- ğŸ” Search Kaggle datasets by **multiple keywords & pages**
- ğŸ“¦ Download datasets with **pre-check size limit (â‰¤ 2GB per dataset)**
- ğŸ“Š Filter CSV files by:
  - Row count
  - Column count
  - Content hash (global deduplication)
- ğŸ§  **Per-dataset CSV selection (max 5)**
  - Prefer different table names (file-name based)
- ğŸ§¾ Generate a comprehensive `index.csv`
- ğŸ§¹ Automatic cleanup of temporary files
- ğŸ” Built-in retry & rate-limit mitigation
- ğŸ›¡ï¸ Handles **CSV filename encoding / garbled text issues**

---

## Output Structure

```
kaggle_pool/
â”œâ”€â”€ all_csv/            # Final accepted CSV files
â”‚   â”œâ”€â”€ sales_2022_a91c2f3e12.csv
â”‚   â”œâ”€â”€ train_b83d91a44e.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ index.csv           # Metadata index of all collected CSVs
â””â”€â”€ raw_datasets/       # Temporary downloads (auto-deleted)
```

---

## Filtering Rules

### Dataset-level
- **Total dataset size â‰¤ 2048 MB**
- If dataset size cannot be determined:
  - Can be allowed (configurable)
  - Still checked again after download

### CSV-level
| Constraint | Default |
|---|---|
| Min rows | 300 |
| Max rows | 50,000 |
| Min columns | 4 |
| Max CSVs per dataset | 5 |
| Deduplication | Global MD5 hash |

---

## Table Name Logic

In this project, **table name is derived from the CSV filename**, not from headers.

Example:

| Filename | Table name signature |
|---|---|
| `train_1.csv` | `train` |
| `train_2.csv` | `train` |
| `test.csv` | `test` |

Selection strategy:
1. Prefer CSVs with **different table name signatures**
2. If fewer than 5 are found, allow duplicates to fill up

---

## index.csv Schema

| Column | Description |
|---|---|
| `filename` | Final saved CSV filename |
| `rows` | Number of rows |
| `cols` | Number of columns |
| `size_kb` | File size (KB) |
| `md5` | Content hash |
| `source` | Kaggle dataset reference |
| `keyword` | Search keyword |
| `name_sig` | Normalized table name |
| `orig_zip_name` | Original filename inside zip |
| `fixed_zip_name` | Filename after encoding fix |

---

## Requirements

- Python 3.8+
- Kaggle CLI

Install Kaggle CLI:

```
pip install kaggle
```

---

## Authentication

A valid **Kaggle API Token** is required.

âš ï¸ **Never commit real API tokens to GitHub.**

---

## Usage

```
python kaggle_downlaod.py
```

The script is designed for **long-running execution** and tolerates:
- Network instability
- Kaggle API rate limiting
- Partial failures

---

## Disclaimer

This project uses the official Kaggle CLI.  
Users are responsible for complying with Kaggleâ€™s Terms of Service.
